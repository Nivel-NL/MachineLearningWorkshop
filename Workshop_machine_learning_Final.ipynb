{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ZtK6eIjXCb-5",
        "1-6uIbEfkxbU",
        "BRSK6Q09Uyh-",
        "iF89tazQlbBm",
        "MqLBLCndDWGP",
        "9haWFT54H59d",
        "Ms1qliKPfkL1",
        "gPkQ_1zXlsmv",
        "DUZtPc6-PusZ",
        "Kjk7SSxUcZhK",
        "9oH0Ab0x7v1O",
        "1MiDbe4aBcTb",
        "q3Eh9I6vEPtW"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Workshop Machine Learning Nivel**\n",
        "\n",
        "---\n",
        "\n",
        "## Benodigde onderdelen om te beginnen\n",
        "\n"
      ],
      "metadata": {
        "id": "ZtK6eIjXCb-5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###In dit stukje worden de noodzakelijke bibliotheken geinstalleerd die nodig zijn voor data verwerking, visualisatie en machine learning\n"
      ],
      "metadata": {
        "id": "1-6uIbEfkxbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px"
      ],
      "metadata": {
        "id": "l09alaIQk6L0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hier wordt de dataset ingeladen\n",
        "\n"
      ],
      "metadata": {
        "id": "fQGCSzYrlFDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Datafile.csv')"
      ],
      "metadata": {
        "id": "1GL2HSSyjY1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "# **Comments voor de verwerking**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BRSK6Q09Uyh-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra informatie:\n",
        "\n",
        "### 1. Een patient met hartfalen wordt als 1 aangeduid, een patient zonder hartfalen als 0.\n",
        "### 2. De aanwezigheid van hartfalen wordt 'target' genoemd\n",
        "### 3. Er zijn soms 'extra vragen' toegevoegd: Dit is voor verdere verdieping mocht je tijd over hebben"
      ],
      "metadata": {
        "id": "tr2D9GxIU7_I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        " \n",
        "#**Deel 1 - Data Preparatie**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "iF89tazQlbBm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## De eerste stap is altijd het bekijken van de data. Hier doen we dit door:\n",
        "### 1). De tabel zelf te bekijken\n",
        "### 2). De verdeling cases / controls te bekijken\n",
        "### 3). Scatterplots van variabelen te bekijken\n",
        "### 4). Histogrammen van data te bekijken\n"
      ],
      "metadata": {
        "id": "zvabfaAiB7b4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bekijk je tabel door het runnen van deze cel\n",
        "df"
      ],
      "metadata": {
        "id": "HhA-l4BXkNCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bekijk de verdeling cases: Controls\n",
        "df['target'].sum() / df['target'].count()"
      ],
      "metadata": {
        "id": "W6ux_l_8IIPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualiseer relaties tussen variabelen\n",
        "# 2D scatterplot of two variables\n",
        "px.scatter(df, x='Leeftijd (continue)', y='BMI', color = 'target')"
      ],
      "metadata": {
        "id": "zcHSXkSoljyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##`Vraag 1: Wat valt je op?`\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MqLBLCndDWGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Opdracht: Pas onderstaande code aan om zelf een 2d scatterplot te maken tussen twee variabelen\n",
        "px.scatter(df, x='', y='', color = 'target')"
      ],
      "metadata": {
        "id": "Jb9kyt0nHwdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Maak een histogram van een variabele gesplitst op de outcome. Je kan de code aanpassen om andere variabelen te tonen. Wat zie je?\n",
        "import plotly.graph_objects as go\n",
        "import plotly.figure_factory as ff\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Histogram(x=df.loc[df['target']==0,'Leeftijd (continue)'].values, histnorm='percent'))\n",
        "fig.add_trace(go.Histogram(x=df.loc[df['target']==1,'Leeftijd (continue)'].values, histnorm='percent'))"
      ],
      "metadata": {
        "id": "9oEFg6Rcl_Ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Het is zichtbaar dat datasoorten verschillen in de dataset (continu vs noncontinu), de ranges sterk verschillen en er een flinke imbalans in de ratio case:controls is. Belangrijker echter is dat er duidelijk artefacten in de data zitten (cellen met de waarde 999), evenals lege cellen (cellen met de waarde NaN). Dit kunnen we bekijken en verhelpen"
      ],
      "metadata": {
        "id": "p5moerfBfLR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Toon per variabele het aantal artifacten. Neem ook in gedachten hoeveel patienten er totaal waren. \n",
        "(df==999).sum()"
      ],
      "metadata": {
        "id": "3LUSFxHexvKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### En voor de lege cellen:"
      ],
      "metadata": {
        "id": "ZsdZhsZjJVaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aantal lege cellen per parameter. \n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "S1BWO7VNxmnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##`Vraag 2: Met welke variabelen kan je nog niet aan de slag zonder voorbewerking?`"
      ],
      "metadata": {
        "id": "9haWFT54H59d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dat zijn een redelijk aantal missings en artifacten! Omdat artifactverwijdering en NaN imputatie standaard operaties zijn in statistiek, gaan we ze hier niet uitgebreid bespreken. Hier worden de artifacten vervangen door NaNs, waarna alle NaNs geimputeerd worden door de mean (continue waarde) of median (non-oontinue waarde)."
      ],
      "metadata": {
        "id": "Ms1qliKPfkL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Artifacten naar NaNs omzetten\n",
        "mask = df==999\n",
        "df[mask] = np.nan"
      ],
      "metadata": {
        "id": "gSisZojByKw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aantal NaNs aanwezig\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "6dRM-3i-yj9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imputatie. Hier hoef je niet perse diep op in te gaan; Het kan wel interessant zijn\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Select which parameters are continuous\n",
        "non_continuous = ['Chronische aandoeningen', 'Geslacht','Polyfarmacie','rGFR','AF', 'Alcoholmisbruik','COVID doorgemaakt','COPD','Slaapproblemen']\n",
        "continuous = [x for x in df.columns if x not in non_continuous]\n",
        "\n",
        "# Impute continuous values based on the mean\n",
        "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "imp_mean.fit(df[continuous])\n",
        "df[continuous] = imp_mean.transform(df[continuous])\n",
        "\n",
        "# Impute non-continuous values based on the mode\n",
        "imp_mode = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
        "imp_mode.fit(df[non_continuous])\n",
        "df[non_continuous] = imp_mode.transform(df[non_continuous])\n",
        "\n",
        "# Some values should be rounded\n",
        "to_round = ['Aantal consulten huisarts jaar ervoor', 'Leeftijd (continue)']\n",
        "for param in to_round:\n",
        "  df[param] = np.round(df[param])"
      ],
      "metadata": {
        "id": "05Mh01f-wjRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Opdracht: Kijk opnieuw naar de scatterplot. Probeer ook andere grafieken te maken om je data te valideren. Zijn de artifacten verdwenen?\n",
        "px.scatter(df, x='Leeftijd (continue)', y='Pro-BNP (pg/ml)', color = 'target')"
      ],
      "metadata": {
        "id": "h82DTFQoJhif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##`Vraag 3: Heb je al een idee welke variabelen voorspellend zouden kunnen zijn voor je uitkomst?`\n",
        "\n"
      ],
      "metadata": {
        "id": "P2fF5FGXW7x0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing is klaar: Hoewel dit hier snel is gedaan omdat de data al goed verzorgd is, is dit meestal de belangrijkste stap in het ontwikkelen van een ML model. Onthoud: Garbage in is garbage out. Een veel gemaakte fout is het blind toepassen van ML technieken, wat dan leidt tot slechte of onjuiste resultaten. Daarom: Mocht je dus een model ontwikkelen, leg een sterke focus op de data preprocessing."
      ],
      "metadata": {
        "id": "mxlq2gFvFhL6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##`Extra vraag: De preprocessing is nu grof gedaan. Zou je dit anders aanpakken, en zo ja, hoe?`"
      ],
      "metadata": {
        "id": "uKv-rkr0XL-l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "#**Deel 2 - Machine learning modellen bouwen en interpreteren**\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "gPkQ_1zXlsmv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###We gaan verder met ML modellen bouwen. Waarom willen we eigenlijk ML modellen bouwen, en niet een simpele logistische regressie? Dit komt doordat complexere modellen complexere (non-lineaire) verbanden mee kunnen nemen.\n",
        "###We beginnen met een decision tree, en nemen steeds ook logistische regressie mee. Een decision tree is vergelijkbaar met een klinische beslisboom: Bij iedere stap is er een indien dit, dan dit, anders dat (e.g. if age <20, ga links, anders, ga rechts). Zo wordt er een boom gebouwd, met aan de onderkant een classificatie.\n",
        "\n"
      ],
      "metadata": {
        "id": "yYcNs7Kz_3Ok"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##`Vraag 4: Heb je een idee wat de uitkomsten (accuracy) van de beslisboom en de logistische regressie zullen / kunnen zijn? Waarom?`"
      ],
      "metadata": {
        "id": "bh8vsWe6YOdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hier wordt een logistische regressie en een beslisboom gemaakt\n",
        "\n",
        "# Importeer de benodigde packages\n",
        "#from sklearn.preprocessing import StandardScaler\n",
        "#from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# We geven handmatig aan welke parameters we mee willen nemen voor trainen. Dit is niet perse de meest efficiente manier, maar toont het verschil goed aan.\n",
        "parameters_toInclude = ['Pro-BNP (pg/ml)','BMI','Aantal consulten huisarts jaar ervoor','Chronische aandoeningen',\n",
        "            'Leeftijd (continue)', 'Geslacht','Polyfarmacie','rGFR','AF', 'Alcoholmisbruik','COVID doorgemaakt','COPD','totaal cholesterol (mmol/l)','Slaapproblemen','target']\n",
        "\n",
        "#------------------ Logistische regressie -------------------------------------#\n",
        "# Geef aan welk model er wordt gebruikt\n",
        "print('Start met trainen van het LR model')\n",
        "model = LogisticRegression(max_iter=2000)\n",
        "\n",
        "# Bij de training moet je de input data aangeven (waar je op traint), evenals de uitkomst data (de labels, hier 'target' in het dataframe)\n",
        "# We geven hier dus het volledige dataframe als input, en de labels als target\n",
        "model.fit(df[parameters_toInclude], df['target'])\n",
        "print('LR model is getraind')\n",
        "\n",
        "# Score het model\n",
        "modelscore = model.score(df[parameters_toInclude], df['target'])\n",
        "print('Het LR model heeft een accuratesse van: {}\\n'.format(modelscore))\n",
        "\n",
        "\n",
        "# ------------------ Decision tree --------------------------------------------#\n",
        "# Geef aan welk model er wordt gebruikt\n",
        "print('Start met trainen van de decision tree')\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "# Bij de training moet je de input data aangeven (waar je op traint), evenals de uitkomst data (de labels, hier 'target' in het dataframe)\n",
        "# We geven hier dus het volledige dataframe als input, en de labels als target\n",
        "model.fit(df[parameters_toInclude], df['target'])\n",
        "print('De decision tree is getraind')\n",
        "\n",
        "# Score het model\n",
        "modelscore = model.score(df[parameters_toInclude], df['target'])\n",
        "print('De decision tree heeft een accuratesse van: {}\\n'.format(modelscore))"
      ],
      "metadata": {
        "id": "G2Z6mooIEOCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##`Vraag 5: Wat komt er uit de analyse? Komt dit overeen met je verwachtingen? Waarom wel en waarom niet, en wat kunnen we eraan doen? Zou je een LR model gebruiken of een decision tree?`\n",
        "\n",
        "-> In de verborgen code meer uitleg: Klik daarop"
      ],
      "metadata": {
        "id": "h9-zktoJJjk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Het probleem is dat we de volledige dataframe als input hebben gegeven: Hier zit ook de target in. \n",
        "#Het model kan heel makkelijk deze 1:1 relatie eruit halen, en dus altijd goed voorspellen. \n",
        "#Dit geeft aan hoe makkelijk een foutje gemaakt kan worden, en wat voor effecten dit kan hebben. \n",
        "\n",
        "# Laten we dit rechtzetten, en nu trainen zonder de input erin te stoppen."
      ],
      "metadata": {
        "id": "Nr18uSY8J3hG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### De aanpassing die hierboven beschreven staat voeren we hier door"
      ],
      "metadata": {
        "id": "Ncn7d5VvKDLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We geven handmatig aan welke parameters we mee willen nemen voor trainen. Dit is niet perse de meest efficiente manier, maar toont het verschil goed aan.\n",
        "parameters_toInclude = ['Pro-BNP (pg/ml)','BMI','Aantal consulten huisarts jaar ervoor','Chronische aandoeningen',\n",
        "            'Leeftijd (continue)', 'Geslacht','Polyfarmacie','rGFR','AF', 'Alcoholmisbruik','COVID doorgemaakt','COPD','totaal cholesterol (mmol/l)','Slaapproblemen']\n",
        "\n",
        "#------------------ Logistische regressie -------------------------------------#\n",
        "# Geef aan welk model er wordt gebruikt\n",
        "print('Start met trainen van het LR model')\n",
        "model = LogisticRegression(max_iter=2000)\n",
        "\n",
        "# Bij de training moet je de input data aangeven (waar je op traint), evenals de uitkomst data (de labels, hier 'target' in het dataframe)\n",
        "# We geven hier dus niet meer het label mee als input\n",
        "model.fit(df[parameters_toInclude], df['target'])\n",
        "print('Model is getraind')\n",
        "\n",
        "# Score het model\n",
        "modelscore = model.score(df[parameters_toInclude], df['target'])\n",
        "print('Het model heeft een accuratesse van: {}\\n'.format(modelscore))\n",
        "\n",
        "# ------------------ Decision tree --------------------------------------------#\n",
        "# Geef aan welk model er wordt gebruikt\n",
        "print('Start met trainen van de decision tree')\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "# Bij de training moet je de input data aangeven (waar je op traint), evenals de uitkomst data (de labels, hier 'target' in het dataframe)\n",
        "# We geven hier dus niet meer het label mee als input\n",
        "model.fit(df[parameters_toInclude], df['target'])\n",
        "print('Decision tree is getraind')\n",
        "\n",
        "# Score het model\n",
        "modelscore = model.score(df[parameters_toInclude], df['target'])\n",
        "print('De decision tree heeft een accuratesse van: {}\\n'.format(modelscore))\n"
      ],
      "metadata": {
        "id": "R6PS1JLnFjJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Het nieuwe model is nu niet getraind met per ongeluk de labels erin.\n",
        "\n",
        "##`Vraag 6: Wat vind je nu van de accuracy van beide modellen? Waarom?`\n"
      ],
      "metadata": {
        "id": "uLzqPuBlPVcO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Het is goed om op te merken dat de case: control ratio 0.1 is... Oftewel, een sterke imbalance.\n",
        "\n",
        "##`Vraag 7: Als je dit meeneemt, wat vind je nu van de accuracy? Kun je de uitkomst verklaren? En is accuracy dan nog wel een goede maat?`"
      ],
      "metadata": {
        "id": "j5H_-c1kZj7k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Om dit eerlijker te kunnen bekijken, introduceren we de ROC curve en de AUC erbij. Hierbij is de optimale waarde van de AUC 1, en de ROC curve is optimaal als hij in de linkerbovenhoek plakt."
      ],
      "metadata": {
        "id": "_rknyWQMZ2Ub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, RocCurveDisplay\n",
        "\n",
        "#------------------ Logistische regressie -------------------------------------#\n",
        "# Geef aan welk model er wordt gebruikt\n",
        "print('Start met trainen van het LR model')\n",
        "model = LogisticRegression(max_iter=2000)\n",
        "\n",
        "# Bij de training moet je de input data aangeven (waar je op traint), evenals de uitkomst data (de labels, hier 'target' in het dataframe)\n",
        "# We geven hier dus niet meer het label mee als input\n",
        "model.fit(df[parameters_toInclude], df['target'])\n",
        "print('Model is getraind')\n",
        "\n",
        "# Maak een predictie op de data met het model\n",
        "prediction = model.predict_proba(df[parameters_toInclude])[:, 1]\n",
        "\n",
        "# Toon de ROC curve\n",
        "RocCurveDisplay.from_predictions(df['target'], prediction)\n",
        "print('AUC van de ROC curve met het LR model: {}'.format(roc_auc_score(df['target'], prediction)))\n",
        "\n",
        "# ------------------ Decision tree --------------------------------------------#\n",
        "# Geef aan welk model er wordt gebruikt\n",
        "print('Start met trainen van de decision tree')\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "# Bij de training moet je de input data aangeven (waar je op traint), evenals de uitkomst data (de labels, hier 'target' in het dataframe)\n",
        "# We geven hier dus niet meer het label mee als input\n",
        "model.fit(df[parameters_toInclude], df['target'])\n",
        "print('Decision tree is getraind')\n",
        "\n",
        "# Maak een predictie op de data met het model\n",
        "prediction = model.predict_proba(df[parameters_toInclude])[:, 1]\n",
        "\n",
        "# Toon de ROC curve en de AUC\n",
        "RocCurveDisplay.from_predictions(df['target'], prediction)\n",
        "print('AUC van de ROC curve met de decision tree: {}'.format(roc_auc_score(df['target'], prediction)))"
      ],
      "metadata": {
        "id": "1ZKLABueIUMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##`Vraag 8: Wat vind je van deze resultaten? Zijn ze logisch? Welk model vind jij dat de beste voorspellende waarde heeft?`\n",
        "\n",
        "\n",
        "\n",
        "### We weten nu hoe ons model presteert. Dan willen we dit testen op nieuwe patienten. Vanwege de resultaten vervolgen we dit enkel met de decision tree, omdat duidelijk is wat ML kan toevoegen."
      ],
      "metadata": {
        "id": "tu3Sx5X8OWt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Laad de nieuwe patienten:\n",
        "df_test = pd.read_csv('TestPatienten2.csv')\n",
        "\n",
        "# Test de score en AUC voor de nieuwe patienten:\n",
        "modelscore = model.score(df_test[parameters_toInclude], df_test['target'])\n",
        "print('Het model heeft een accuratesse op de nieuwe patienten van: {}'.format(modelscore))\n",
        "\n",
        "prediction = model.predict_proba(df_test[parameters_toInclude])[:, 1]\n",
        "print('AUC van de ROC curve op de nieuwe patienten: {}'.format(roc_auc_score(df_test['target'], prediction)))"
      ],
      "metadata": {
        "id": "Ok7cxWl9QvjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##`Vraag 9: Wat vind je van deze resultaten op de test set? Zijn ze logisch?`"
      ],
      "metadata": {
        "id": "xFpWzzr9Bxc2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##`Extra vraag: Probeer eens om een logistisch regressie model te maken, en deze te testen op de test set. Kun je de uitkomsten hiervan verklaren, ook in relatie tot de uitkomsten van de beslisboom?`"
      ],
      "metadata": {
        "id": "SNE6Bsi9a7wp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "#**Deel 3 - Crossvalidatie en overfitten**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "DUZtPc6-PusZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We zagen in het vorige gedeelte dat de data heel goed op de training set werkte, maar veel minder op de test set. Wellicht heeft de beslisboom dus te specifiek op de training set gefit. Laten we eens naar de beslisboom kijken."
      ],
      "metadata": {
        "id": "T3N8xTYXUujc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "# Geef aan welk model er wordt gebruikt\n",
        "print('Start met trainen van de decision tree')\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "# Bij de training moet je de input data aangeven (waar je op traint), evenals de uitkomst data (de labels, hier 'target' in het dataframe)\n",
        "# We geven hier dus niet meer het label mee als input\n",
        "model.fit(df[parameters_toInclude], df['target'])\n",
        "print('Decision tree is getraind')\n",
        "\n",
        "# Exporteer de figuur van de boom naar de Tree-full.png file\n",
        "import graphviz \n",
        "import pydot\n",
        "\n",
        "dot_data = tree.export_graphviz(model, out_file='Tree_full.dot', \n",
        "                                feature_names=parameters_toInclude,  \n",
        "                                class_names=['Gezond','Patient'],\n",
        "                                filled=True)\n",
        "\n",
        "(graph_tosave,) = pydot.graph_from_dot_file('Tree_full.dot')\n",
        "graph_tosave.write_png('Tree_full.png')\n",
        "\n",
        "# Plot de boom zelf\n",
        "dot_data = tree.export_graphviz(model, out_file=None, \n",
        "                                feature_names=parameters_toInclude,  \n",
        "                                class_names=['Gezond','Patient'],\n",
        "                                filled=True)\n",
        "\n",
        "graph = graphviz.Source(dot_data, format=\"png\")\n",
        "graph"
      ],
      "metadata": {
        "id": "IHiDN_QaPX7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##`Vraag 10: Laten we eens kijken naar de beslisboom zelf: Hoe specifiek heeft deze gefit? (let op: het kan even duren voordat deze zichtbaar wordt: Je kan ook de Tree_full.png downloaden na het runnen om op je pc zelf te kijken). Is hier sprake van te specifieke training naar jouw mening?`"
      ],
      "metadata": {
        "id": "DyFsbMw_IUuN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Een gevaar van overfitting is dat je een hele goede performance op je training set hebt, maar het model niet 'generaliseerbaar' is: Oftewel, het presteert op nieuwe patienten niet net zo goed.\n",
        "\n",
        "### Het is daarom belangrijk om te weten hoe je model het gaat doen op nieuwe data; Dan weet je de 'echte' performance. Daarom hebben we crossvalidatie nodig. We splitsen de dataset in 5 stukken (folds), waarbij we trainen op 4 folds, en testen op 1 fold. De testfold is niet meegenomen in de training, en is dus 'nieuwe' data voor het model. Dit wordt 5x gedaan: Iedere keer met een andere testfold.\n",
        "\n",
        "### Voor de volledigheid wordt dit hier gedaan met een 'stratified' crossvalidatie. Dit zorgt ervoor dat in iedere fold de ratio cases:controls gelijk blijft."
      ],
      "metadata": {
        "id": "mRHZjVvlWLf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importeer benodigde packages\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Maak de crossvalidatie\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "\n",
        "# Overig, niet belangrijk\n",
        "count=1\n",
        "\n",
        "# Parameters om mee te nemen\n",
        "parameters_toInclude = ['Pro-BNP (pg/ml)','BMI','Aantal consulten huisarts jaar ervoor','Chronische aandoeningen',\n",
        "            'Leeftijd (continue)', 'Geslacht','Polyfarmacie','rGFR','AF', 'Alcoholmisbruik','COVID doorgemaakt','COPD','totaal cholesterol (mmol/l)','Slaapproblemen']\n",
        "\n",
        "# De dataframe en de target wordt hier alvast met de juiste parameters gedefinieerd, omdat dat nodig is (niet belangrijk)\n",
        "df_onlyGoodParam = df[parameters_toInclude]\n",
        "target = df['target']\n",
        "\n",
        "\n",
        "# Deze loop loopt selecteert iedere keer een andere split.\n",
        "# De train_index zijn alle patienten in de training set.\n",
        "# De test_index zijn alle patienten in de test set.\n",
        "# Voor iedere split wordt een model gemaakt, en de performance berekent (zoals hierboven al eerder gedaan).\n",
        "\n",
        "for train_index, test_index in skf.split(df_onlyGoodParam, target):\n",
        "  print('--------------- SPLIT NUMMER {} -------------------------'.format(count))\n",
        "\n",
        "    # Geef aan welk model er wordt gebruikt\n",
        "  print('Start met trainen van de decision tree')\n",
        "  model = DecisionTreeClassifier()\n",
        "\n",
        "  # Bij de training moet je de input data aangeven (waar je op traint), evenals de uitkomst data (de labels, hier 'target' in het dataframe)\n",
        "  # We geven hier dus niet meer het label mee als input\n",
        "  # De training index (de train set) wordt als input gegeven.\n",
        "  model.fit(df_onlyGoodParam.iloc[train_index,:], target.iloc[train_index])\n",
        "  print('Decision tree is getraind')\n",
        "\n",
        "  # Performance op de training folds:\n",
        "  modelscore = model.score(df_onlyGoodParam.iloc[train_index,:], target.iloc[train_index])\n",
        "  print('Accuratesse op de training folds: {}'.format(modelscore))\n",
        "\n",
        "  prediction = model.predict_proba(df_onlyGoodParam.iloc[train_index])[:, 1]\n",
        "  print('AUC van de ROC curve op de training folds: {}'.format(roc_auc_score(target.iloc[train_index], prediction))) \n",
        "\n",
        "  # Performance op de test folds:\n",
        "  modelscore = model.score(df_onlyGoodParam.iloc[test_index,:], target.iloc[test_index])\n",
        "  print('Accuratesse op de test folds: {}'.format(modelscore))\n",
        "\n",
        "  prediction = model.predict_proba(df_onlyGoodParam.iloc[test_index])[:, 1]\n",
        "  print('AUC van de ROC curve op de test folds: {}\\n'.format(roc_auc_score(target.iloc[test_index], prediction))) \n",
        "\n",
        "  # Overig\n",
        "  count = count+1\n"
      ],
      "metadata": {
        "id": "XoqEhtIUPX-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##`Vraag 11: Wat zie je in de performance tussen de folds? En in iedere fold tussen de train en test set? Kun je dit verklaren?`"
      ],
      "metadata": {
        "id": "XY8F9FlIdV98"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Een manier om deze overfitting aan te pakken is om de decision tree minder diep te laten trainen. Dus oftewel: De decision tree die we zagen, af te kappen na een diepte van x keer splitten. Probeer dit eens uit door in de bovenstaande code in de syntax 'DecisionTreeClassifier()' tussen de haakjes max_depth=x in te voegen, met de x een waarde naar je keuze. Probeer ook eens verschillende waardes van x uit. \n",
        "\n",
        "##`Vraag 12: Wat gebeurt er? Kun je dit verklaren? Als je wilt kun je onderstaande syntax runnen om de laatste beslisboom die je trainde weer te inspecteren.`"
      ],
      "metadata": {
        "id": "La1M32UEbUzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "\n",
        "# Exporteer de figuur van de boom naar de Tree_part.png file\n",
        "dot_data = tree.export_graphviz(model, out_file='Tree_part.dot', \n",
        "                                feature_names=parameters_toInclude,  \n",
        "                                class_names=['Gezond','Patient'],\n",
        "                                filled=True)\n",
        "\n",
        "(graph_tosave,) = pydot.graph_from_dot_file('Tree_part.dot')\n",
        "graph_tosave.write_png('Tree_part.png')\n",
        "\n",
        "# Plot de boom zelf\n",
        "dot_data = tree.export_graphviz(model, out_file=None, \n",
        "                                feature_names=parameters_toInclude,  \n",
        "                                class_names=['Gezond','Patient'],\n",
        "                                filled=True)\n",
        "\n",
        "graph = graphviz.Source(dot_data, format=\"png\")\n",
        "graph"
      ],
      "metadata": {
        "id": "Yk6VOHdTPYAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##`Vraag 13: Nu we een aangepast model hebben, en het overfitting iets hebben tegengegaan, hoe presteert dit op de nieuwe patienten? Hiervoor laden we opnieuw de dataset in, en testen we het wederom. Hoe doet het het nu?`"
      ],
      "metadata": {
        "id": "VlzLtmSWAc0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Laad de nieuwe patienten:\n",
        "df_test = pd.read_csv('TestPatienten2.csv')\n",
        "\n",
        "# Test de score en AUC voor de nieuwe patienten:\n",
        "modelscore = model.score(df_test[parameters_toInclude], df_test['target'])\n",
        "print('Het model heeft een accuratesse op de nieuwe patienten van: {}'.format(modelscore))\n",
        "\n",
        "prediction = model.predict_proba(df_test[parameters_toInclude])[:, 1]\n",
        "print('AUC van de ROC curve op de nieuwe patienten: {}'.format(roc_auc_score(df_test['target'], prediction)))"
      ],
      "metadata": {
        "id": "bm9XlhXBgpK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##`Extra vraag: Wat denk je dat de invloed van een verschillend aantal folds op de performance is, en waarom? Je kan dit uittesten door de n_splits te veranderen (nu 5). Komt dit overeen met je verwachtingen?`"
      ],
      "metadata": {
        "id": "w1_Lwpmwd58j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# **Deel 4: Hyperparameter tuning en feature selectie**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Kjk7SSxUcZhK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wat je in het vorige gedeelte aan het einde deed (het aanpassen van de diepte van de decision tree), was het aanpassen van een zogeheten hyperparameter. Dit zijn modelinstellingen die bepalen hoe een model traint, in dit geval hoe diep een beslisboom traint. Vrijwel ieder model heeft bergen van deze instellingen, en je weet van tevoren niet wat de beste zijn. Wat daarom vaak wordt gedaan is 'hyperparameter tuning'. Hierbij wordt een grote hoeveelheid combinaties van hyperparameters uitgeprobeerd, en wordt simpelweg het beste model gekozen. \n",
        "\n",
        "### Voorbeelden voor de decision tree zijn zijn:\n",
        "#####max_depth=x -> De maximale diepte\n",
        "#####class_weight = 'balanced' of None -> of er een correctie moet komen voor de imbalans in case:controls. Is dat handig hier?\n",
        "#####min_samples_leaf = x -> Hoeveel samples er minimaal per uiteindelijk 'blad' aan de boom moeten zitten\n",
        "\n",
        "### Wanneer je meerdere hyperparameters invoert, zorg dat je deze met een komma scheidt: Dus max_depth=20 , class_weight = 'balanced' (bijvoorbeeld)\n",
        "\n",
        "Op de pagina https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier vind je uitgebreide mogelijkheden mocht je interesse hebben"
      ],
      "metadata": {
        "id": "VDq-Qx-OdwnQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##`Vraag 14: Ga eens terug naar de code waar je de hyperparameters veranderde, en probeer eens wat meerdere variaties uit. Kun je een betere performance halen op de validatie sets? En hoe presteert dit dan op de test set? Kun je dit verklaren?`"
      ],
      "metadata": {
        "id": "bz4nILm6fnEv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ter info: Meestal worden deze parameters binnen een fold gezocht, en dan de beste gevonden parameter getest op de test fold. Hier bestaan standaard algoritmes voor (GridSearchCV in sklearn), zodat dit niet handmatig hoeft te worden geprogrammeerd. Dit valt echter buiten de scope van deze workshop"
      ],
      "metadata": {
        "id": "9oH0Ab0x7v1O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature selectie\n",
        "### Wat we zagen is een totaal van 8000 patienten, en 15 features. Hierdoor kan het model redelijk goed trainen, ook al zijn niet alle features even belangrijk. Dit wordt anders wanneer het aantal features (bijna) even groot is als het aantal patienten: Dan kunnen patronen door kans een voorspellende waarde hebben\n",
        "\n",
        "### Een oplossing hiervoor is feature selectie. Er zijn vele manieren, maar een manier is forward feature selectie. Hierbij wordt steeds een parameter aan het model toegevoegd, tot alle parameters op zijn. Bij iedere stap wordt de performance berekend, waardoor je ziet wanneer meer features toevoegen niet meer helpt.\n",
        "\n",
        "### Hieronder wordt forward feature selectie geimplementeerd en getest op de AUC. Ook wordt de performance per aantal parameters geplot"
      ],
      "metadata": {
        "id": "Kzvfrlt08rYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run deze cel 1x, dan werkt het feature selectie algoritme\n",
        "!pip install mlxtend --upgrade"
      ],
      "metadata": {
        "id": "hSVGnXubEMUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "\n",
        "# Train een forward feature selection algoritme. Dit algoritme begint met een leeg model. Het maakt een crossvalidatie, en voegt dan iedere parameter toe als test (dus als je 15 features hebt, maakt het algoritme 15 modellen met crossvalidatie, ieder met 1 parameter in dit model).\n",
        "# De beste feature gaat in het model, en dan probeert het wederom de rest van de parameters toe te voegen (dus weer 14 testen).\n",
        "# Dit doet het tot alle features op zijn: Het model met het aantal features dat optimaal is wordt dan geselecteerd.\n",
        "# Let wel: Er is een maximale diepte ingesteld voor de decision tree van 6. Als je de parameters in je model gebruikt, moet dit voor het beste resultaat ook de hyperparameter zijn.\n",
        "\n",
        "sfs = SFS(DecisionTreeClassifier(max_depth=6), k_features=14, forward=True,cv=5, scoring = 'roc_auc')\n",
        "sfs.fit(df.iloc[:,:-1], target)"
      ],
      "metadata": {
        "id": "nq0cQPjI8qxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
        "import matplotlib.pyplot as plt\n",
        "fig = plot_sfs(sfs.get_metric_dict(), kind='std_err')\n",
        "\n",
        "plt.title('Sequential Forward Selection ( met SE)')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Qc8Kwp9WAVbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Belangrijk om te weten is per stap de parameters die zijn ingevoegd. Die kun je aflezen door de volgende code te runnen. De feature_names bij {4} stelt bijvoorbeeld de 4 geincludeerde parameters voor bij bovenstaande grafiek op x=4 "
      ],
      "metadata": {
        "id": "GnqHDdbmCbL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run om de parameters per stap af te lezen\n",
        "sfs.get_metric_dict()"
      ],
      "metadata": {
        "id": "ZX01cKhX3Zs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##`Vraag 15: Hoeveel parameters moet je toevoegen voor een optimaal model? Welke parameters zijn dit? Ga eens terug naar je model, en gebruik alleen deze parameters voor het model. Veranderd de performance, en kun je dit verklaren?`\n"
      ],
      "metadata": {
        "id": "1MiDbe4aBcTb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# **Verdere verdieping**\n",
        "\n",
        "---\n",
        "\n",
        "Dit waren de dingen die we graag wilden bespreken in de workshop. Je hebt hopelijk meegenomen:\n",
        "\n",
        "1). Het belang van preprocessing.\n",
        "\n",
        "2). De basis van machine learning modellen.\n",
        "\n",
        "3). Dingen waar je op moet letten bij ML modellen. Denk hierbij ook aan test en train sets!\n",
        "\n",
        "4). Kennis over crossvalidatie en overfitting.\n",
        "\n",
        "5). Belangrijke additionele kennis (hyperparameters, feature selectie).\n",
        "\n",
        "### Mocht je nog verder interesse hebben, kunnen we je de volgende stappen aanraden:\n",
        "\n",
        "1). Probeer bovenstaande analyse eens met een random forest. Dit is als het ware een hoop beslisbomen bij elkaar. Verbetert dit het model?\n",
        "\n",
        "2). Op www.kaggle.com zijn veel datasets te vinden waarmee je kan spelen. Hierbij is ook vaak uitleg aanwezig. Kijk ook eens naar https://www.kaggle.com/learn/intro-to-machine-learning. Extraatje: Als je de beste bent ter wereld, kun je er grote prijzen mee verdienen ;)\n",
        "\n"
      ],
      "metadata": {
        "id": "q3Eh9I6vEPtW"
      }
    }
  ]
}